from stream_answer import stream_ans
from openai import RateLimitError
import streamlit as st
import re

sys_messages=r"""
ä½ æ˜¯é«˜ä¸­æ•°å­¦è€å¸ˆï¼Œæ“…é•¿å›ç­”å­¦ç”Ÿé—®é¢˜,
å›ç­”ä¸­æ•°å­¦å…¬å¼è¾“å‡ºæ ¼å¼å‚è€ƒï¼š\[\(\frac{x^2}{y}\)+\x\times\y \]

"""
#st.session_stateå¯ä»¥å®šä¹‰ä¸è¢«é‡ç½®çš„é‡
def clear_chat_history():
    del st.session_state.history

def init_chat_history():
    with st.chat_message("assistant", avatar='ğŸ¤–'):
        st.markdown("æ‚¨å¥½ï¼Œæˆ‘ æ˜¯IM Teacherï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡")
    #å±•ç¤ºå¯¹è¯ï¼ˆæœ‰äº›æç¤ºè¯ä¸èƒ½å±•ç¤ºï¼‰
    if "history" in st.session_state:
         for message in st.session_state.history:
            if message["role"] == "user":
                with st.chat_message(message["role"], avatar = 'ğŸ§‘'):
                    st.markdown(message["content"])
            if message["role"] == "assistant":
                with st.chat_message(message["role"],avatar = 'ğŸ¤–'):
                    st.markdown(message["content"]) 
    else:
        st.session_state.history = []
    return st.session_state.history

# æç¤ºè¯å‚è€ƒ  https://github.com/codelion/optillm/blob/main/optillm/cot_reflection.py
def cot(system_prompt, user_prompt):
    cot_prompt = """
    {}
    ä½ æ˜¯ä¸€ä¸ªä½¿ç”¨æ€ç»´é“¾ï¼ˆChain of Thoughtï¼Œç®€ç§° CoTï¼‰æ–¹æ³•å¹¶ç»“åˆåæ€æ¥å›ç­”é—®é¢˜çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

    1. åœ¨ `<thinking>` æ ‡ç­¾å†…ï¼Œé€æ­¥æ€è€ƒé—®é¢˜ã€‚
    2. åœ¨ `<reflection>` æ ‡ç­¾å†…ï¼Œåæ€ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯æˆ–å¯ä»¥æ”¹è¿›çš„åœ°æ–¹ã€‚
    3. æ ¹æ®ä½ çš„åæ€ï¼Œè¿›è¡Œå¿…è¦çš„è°ƒæ•´ã€‚
    4. åœ¨ `<output>` æ ‡ç­¾å†…ï¼Œæä¾›ä½ æœ€ç»ˆç®€æ´çš„ç­”æ¡ˆã€‚

    **é‡è¦æç¤º**ï¼š`<thinking>` å’Œ `<reflection>` éƒ¨åˆ†ä»…ç”¨äºä½ è‡ªå·±çš„å†…éƒ¨æ¨ç†è¿‡ç¨‹ã€‚ä¸è¦åœ¨è¿™äº›éƒ¨åˆ†åŒ…å«ä»»ä½•æœ€ç»ˆç­”æ¡ˆçš„å†…å®¹ã€‚å¯¹æŸ¥è¯¢çš„å®é™…å›ç­”å¿…é¡»å®Œå…¨åŒ…å«åœ¨ `<output>` æ ‡ç­¾å†…ã€‚

    è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç»™å‡ºä½ çš„å›ç­”ï¼š

    <thinking>
    [ä½ çš„é€æ­¥æ¨ç†è¿‡ç¨‹å†™åœ¨è¿™é‡Œã€‚è¿™æ˜¯ä½ çš„å†…éƒ¨æ€è€ƒè¿‡ç¨‹ï¼Œä¸æ˜¯æœ€ç»ˆç­”æ¡ˆã€‚]
    <reflection>
    [ä½ å¯¹è‡ªå·±æ¨ç†è¿‡ç¨‹çš„åæ€ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯æˆ–å¯ä»¥æ”¹è¿›çš„åœ°æ–¹]
    </reflection>
    [æ ¹æ®ä½ çš„åæ€å¯¹æ€è€ƒè¿‡ç¨‹åšå‡ºçš„ä»»ä½•è°ƒæ•´]
    </thinking>
    <output>
    [ä½ å¯¹æŸ¥è¯¢çš„æœ€ç»ˆç®€æ´å›ç­”ã€‚è¿™å°†æ˜¯å”¯ä¸€å±•ç¤ºç»™ç”¨æˆ·çš„å†…å®¹ã€‚]
    </output>

    """.format(system_prompt)
    history=[
            {"role": "system", "content": cot_prompt},
            {"role": "user", "content": user_prompt}
        ]
    response = stream_ans(history)
    return response
   

def main():
        init_chat_history()
        if prompt := st.chat_input("Shift + Enter æ¢è¡Œ, Enter å‘é€"):
            with st.chat_message("user", avatar='ğŸ§‘'):
                st.markdown(prompt)
            response=cot(sys_messages,prompt)
             # è¾“å‡ºæ€è€ƒç»“æœ
            if response:
                match = re.search(r"<output>(.*?)(?:</output>|$)", response, re.DOTALL)
                result= match.group(1).strip() if match else response
                st.session_state.history.append({"role": "user", "content": prompt})
                st.session_state.history.append({"role": "assistant", "content": response})
                st.session_state.history.append({"role": "assistant", "content": result})
                st.button("æ¸…ç©ºå¯¹è¯", on_click=clear_chat_history)
                with st.chat_message("assistant", avatar='ğŸ¤–'):
                    st.markdown(result)
                return result
            else: return ""

if __name__ == "__main__":
    main()